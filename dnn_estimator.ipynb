{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# get data through tensorflow MNIST tutorials Data.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train.cls = np.argmax(data.train.labels, axis = 1)\n",
    "data.test.cls = np.argmax(data.test.labels, axis = 1)\n",
    "data.train.labels[0:10] #setting 10 labels to test later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting paramters\n",
    "\n",
    "img_size = 28\n",
    "img_size_flat = img_size * img_size \n",
    "img_shape = (img_size, img_size)\n",
    "num_channels = 1\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than providing raw data directly to the Estimator, we must provide functions that return the data. This allows for more flexibility in data-sources and how the dta is randomly shutffled and iterated.\n",
    "\n",
    "Note that we will create an Estimator with DNNClassifier, which assumes the class-numbers are integers so we use data.train.cls instead of data.train.labels which are one-hot encoded arrays.\n",
    "\n",
    "The function also had paramters for batch_size, que_capacity and num_threads for finer control of the data reading. In our case we take the data directly from a numpy array in memory, so it is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(data.train.images)},\n",
    "    y=np.array(data.train.cls),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'x': <tf.Tensor 'random_shuffle_queue_DequeueMany_2:1' shape=(128, 784) dtype=float32>},\n",
       " <tf.Tensor 'random_shuffle_queue_DequeueMany_2:2' shape=(128,) dtype=int64>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling this function returns a tuple with tensorflow ops for returning the input and output data:\n",
    "train_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(data.test.images)},\n",
    "    y=np.array(data.test.cls),\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_images = data.test.images[0:9] # to test few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": some_images},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_images_cls = data.test.cls[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using DNN premade classifier, let's do feature columns.\n",
    "feature_x = tf.feature_column.numeric_column(\"x\", shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [feature_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use 3-layer DNN with 512,256,128 units respectively\n",
    "num_hidden_units = [512, 256, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DNNClassifier constructs the NN for us. We can also specify the activation function and various other parameters. Here, I will use relu for activation function and just specify the number of classes and the directory where the checkpionts will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './checkpoints_1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3c1ffa80f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                  hidden_units=num_hidden_units,\n",
    "                                  activation_fn=tf.nn.relu,\n",
    "                                  n_classes=num_classes,\n",
    "                                  model_dir=\"./checkpoints_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints_1/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into ./checkpoints_1/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.3127608, step = 6001\n",
      "INFO:tensorflow:global_step/sec: 129.426\n",
      "INFO:tensorflow:loss = 3.2103305, step = 6101 (0.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.529\n",
      "INFO:tensorflow:loss = 7.220837, step = 6201 (0.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.715\n",
      "INFO:tensorflow:loss = 0.8946363, step = 6301 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.42\n",
      "INFO:tensorflow:loss = 0.34532276, step = 6401 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.473\n",
      "INFO:tensorflow:loss = 2.1448255, step = 6501 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.221\n",
      "INFO:tensorflow:loss = 0.28282717, step = 6601 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.35\n",
      "INFO:tensorflow:loss = 0.29993218, step = 6701 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.756\n",
      "INFO:tensorflow:loss = 0.3186013, step = 6801 (0.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.438\n",
      "INFO:tensorflow:loss = 1.6702476, step = 6901 (0.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.494\n",
      "INFO:tensorflow:loss = 0.6388529, step = 7001 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.892\n",
      "INFO:tensorflow:loss = 3.0667455, step = 7101 (0.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.307\n",
      "INFO:tensorflow:loss = 0.6754796, step = 7201 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.364\n",
      "INFO:tensorflow:loss = 0.49239948, step = 7301 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.248\n",
      "INFO:tensorflow:loss = 0.8006694, step = 7401 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.223\n",
      "INFO:tensorflow:loss = 0.26345888, step = 7501 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.711\n",
      "INFO:tensorflow:loss = 0.18938029, step = 7601 (0.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.349\n",
      "INFO:tensorflow:loss = 0.3104952, step = 7701 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.537\n",
      "INFO:tensorflow:loss = 0.5397639, step = 7801 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.605\n",
      "INFO:tensorflow:loss = 0.5632225, step = 7901 (0.686 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into ./checkpoints_1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.7392746.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f3c1ffaee10>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "\n",
    "# Train the model for a given number of iterations. It automatically loads and saves checkpoints so we can continue training later.\n",
    "\n",
    "model.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-27-20:34:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints_1/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-27-20:34:32\n",
      "INFO:tensorflow:Saving dict for global step 8000: accuracy = 0.9731, average_loss = 0.13056402, global_step = 8000, loss = 16.52709\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: ./checkpoints_1/model.ckpt-8000\n"
     ]
    }
   ],
   "source": [
    "#Evalution\n",
    "\n",
    "result = model.evaluate(input_fn = test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9731,\n",
       " 'average_loss': 0.13056402,\n",
       " 'loss': 16.52709,\n",
       " 'global_step': 8000}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "\n",
    "# note that the tensorflow graph is recreated and the checkpoint is reloaded everytime we make predictions on new data.\n",
    "# if the model is very large then this could add a significant overhead.\n",
    "\n",
    "# this method will not return the entire prediction dataset at once but it returns a python generator \n",
    "# which we can use to iterate through the predictions one by one\n",
    "# first we initialize our generator\n",
    "\n",
    "predictions = model.predict(input_fn=predict_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints_1/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([b'7'], dtype=object),\n",
       " array([b'2'], dtype=object),\n",
       " array([b'1'], dtype=object),\n",
       " array([b'0'], dtype=object),\n",
       " array([b'4'], dtype=object),\n",
       " array([b'1'], dtype=object),\n",
       " array([b'4'], dtype=object),\n",
       " array([b'9'], dtype=object),\n",
       " array([b'5'], dtype=object)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array(list(predictions))\n",
    "cls_pred_1 = [pred[i]['classes'] for i in range(len(pred))]\n",
    "cls_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=np.int(str(list(cls_pred[0])[0])[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred_2 = [np.int(str(list(cls_pred[i])[0])[2]) for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4, 1, 4, 9, 5]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
